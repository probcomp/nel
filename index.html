<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for Robust 6D Pose Estimation">
  <meta name="keywords" content="3DNEL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3DNEL</title>

  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
		  <h1 class="title is-1 publication-title">3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for<br>Robust 6D Pose Estimation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://stanniszhou.github.io/">Guangyao Zhou</a>* <sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://www.nishadg.com/">Nishad Gothoskar</a>* <sup>2</sup>,</span><br>
              <span class="author-block">
                <a href="https://liruiw.github.io/">Lirui Wang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="http://web.mit.edu/cocosci/josh.html">Joshua Tenenbaum</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://research.ibm.com/people/dan-gutfreund">Dan Gutfreund</a><sup>3</sup>,
              </span><br>
              <span class="author-block">
                <a href="https://www.tsc.uc3m.es/~miguel/index.php">Miguel Lazaro-Gredilla</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://dileeplearning.github.io/">Dileep George</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://probcomp.csail.mit.edu/principal-investigator/">Vikash Mansinghka</a><sup>2</sup>
              </span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Google DeepMind</span> &nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>MIT</span>&nbsp;&nbsp;
              <span class="author-block"><sup>3</sup>IBM</span>
            </div>
  
            <div class="is-size-6 publication-authors">
              <span class="author-block">* Equal Contribution</span>
            </div>
  
            <div class="is-size-5 publication-authors">
		    <span class="author-block"><a href="https://iccv2023.thecvf.com/">International Conference on Computer Vision (ICCV) 2023</a></span>
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2302.03744.pdf"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2302.03744"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/google-deepmind/threednel"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">

    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
            <img src="./static/images/teaser_video.gif" />
	    <!-- <div class="content has-text-centered"> -->
		<!-- <p> -->
		<!-- Explanation of the teaser video, giving an overview of what 3DNEL is about. -->
		<!-- </p> -->
	    <!-- </div> -->
        </div>
      </div>



      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The ability to perceive and understand 3D scenes is crucial for many applications
              in computer vision and robotics. Inverse graphics is an appealing approach to 3D scene
              understanding that aims to infer the 3D scene structure from 2D images.
              In this paper, we introduce probabilistic modeling to the inverse graphics framework
              to quantify uncertainty and achieve robustness in 6D pose estimation tasks.
              Specifically, we propose 3D Neural Embedding Likelihood (3DNEL) as a unified probabilistic
              model over RGB-D images, and develop efficient inference procedures on 3D scene
              descriptions. 3DNEL effectively combines learned neural embeddings from RGB with depth
              information to improve robustness in sim-to-real 6D object pose estimation from RGB-D
              images. Performance on the YCB-Video dataset is on par with state-of-the-art yet is
              much more robust in challenging regimes. In contrast to discriminative approaches,
              3DNEL's probabilistic generative formulation jointly models multiple objects in a scene,
              quantifies uncertainty in a principled way, and handles object pose tracking under heavy
              occlusion. Finally, 3DNEL provides a principled framework for incorporating prior
              knowledge about the scene and objects, which allows natural extension to additional tasks
              like camera pose tracking from video.
            </p>
          </div>
        </div>
      </div>
    </div>
    <br><br>
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="content">
            <h2 class="title is-3">3D Neural Embedding Likelihood (3DNEL)</h2>
            <img src="./static/images/likelihood_figure.svg" />
	    <br>
              <div class="content has-text-justified">
              <p>
		3DNEL defines the probability of an observed RGB-D image conditioned on a 3D scene description. We first render the 3D scene description into: (1) a depth image, which is transformed to a rendered point cloud image, (2) a semantic segmentation map, and (3) the object coordinate image (each pixel contains the object frame coordinate of the object surface point from which the pixel originates). The object coordinate image is transformed, via the key models, into key embeddings. The observed RGB image is transformed, via the query models, into query embeddings. The observed depth is transformed into an observed point cloud image. The 3DNEL Energy Function is evaluated using the rendered point cloud image, semantic segmentation, key embeddings, the observed point cloud image, and query embeddings.
              </p>
            </div>
        </div>
      </div>
    </div>
    <br><br>

    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Accurate Sim-to-real Object Pose Estimation</h2>
      </div>
      <br> 
      <div class="columns">
	 <div class="content has-text-justified">
	  <p>
	  We evaluate on the <a href="https://bop.felk.cvut.cz/datasets/">YCB-V</a> dataset from <a href="https://bop.felk.cvut.cz/">Benchmark for 6D Object Pose Estimation</a> in the <b>sim-to-real setup</b>. The reported <a href="https://bop.felk.cvut.cz/challenges/#taskdefinition">average recall metric</a> measures the pose estimation accuracy, and is calculated using the <a href="https://github.com/thodan/bop_toolkit/blob/master/scripts/eval_bop19_pose.py">BOP Toolkit</a>. Higher is better.
	  </p>
	  <p>
	<a href="https://surfemb.github.io/">SurfEMB</a> is the previous SOTA for sim-to-real 6D object pose estimation. For <a href="https://surfemb.github.io/">SurfEMB</a>, <a href="https://github.com/ethnhe/FFB6D">FFB6D</a> and <a href="https://megapose6d.github.io/">MegaPose</a> we use the numbers reported by the authors. For <a href="https://github.com/Simple-Robotics/cosypose">CosyPose</a> and <a href="https://github.com/princeton-vl/Coupled-Iterative-Refinement">Coupled Iterative Refinement</a> we use the publicly available codebases to re-evaluate in the sim-to-real setup. Our proposed 3DNEL Multi-stage Inverse Graphics Pipeline (MSIGP) significantly outperforms previous SOTA.
	  </p>
	 </div>
      </div>
      <br>
      <div class="columns is-centered">
	 <div class="column is-full-width">
	 <div class="content">
	  <table>
            <tr>
              <th><p style="text-align:left">Method</p></th>
	      <th><p style="text-align:center">Average recall on <a href="https://bop.felk.cvut.cz/datasets/">YCB-V</a></p></th>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left">3DNEL Multi-stage Inverse Graphics Pipeline (MSIGP)</a></p></td>
		    <td style="border-bottom: none;"><p style="text-align:center"><b>84.85%</b></p></td>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left"><a href="https://surfemb.github.io/">SurfEMB</a></p></td>
              <td style="border-bottom: none;"><p style="text-align:center">80.00%</p></td>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left"><a href="https://github.com/ethnhe/FFB6D">FFB6D</a></p></td>
              <td style="border-bottom: none;"><p style="text-align:center">75.80%</p></td>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left"><a href="https://megapose6d.github.io/">MegaPose</a></p></td>
              <td style="border-bottom: none;"><p style="text-align:center">63.3%</p></td>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left"><a href="https://github.com/Simple-Robotics/cosypose">CosyPose</a></p></td>
              <td style="border-bottom: none;"><p style="text-align:center">71.42%</p></td>
            </tr>
            <tr>
		    <td style="border-bottom: none;"><p style="text-align:left"><a href="https://github.com/princeton-vl/Coupled-Iterative-Refinement">Coupled Iterative Refinement</a></p></td>
              <td style="border-bottom: none;"><p style="text-align:center">76.58%</p></td>
            </tr>
          </table>
	 </div>
	 </div>
	 <br>

    </div>

    <br>

    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Benefits from Principled Probabilistic Modeling</h2>
      </div>
      <div class="container is-max-desktop">
        <h3 class="title is-4">More Robust Object Pose Estimation</h3>
        
            <!-- <p> -->
	    <!-- Test -->
            <!-- </p> -->
            <br>

        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <img src="./static/images/robustness.png" />
          </div>
        </div>
  
        <div class="columns is-centered has-text-centered">
          <!-- Results. -->
          <div class="column is-four-fifths">
            <div class="content">
            
              <div class="content has-text-justified">
              </div>
              <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                  <div class="item" id="success1">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/1.svg"/>
                  </div>
                  <div class="item" id="success2">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/2.svg"/>
                  </div>
                  <div class="item" id="success3">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/3.svg"/>
                  </div>
                  <div class="item" id="success4">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/4.svg"/>
                  </div>
                  <div class="item" id="success5">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/5.svg"/>
                  </div>
                  <div class="item" id="success6">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/6.svg"/>
                  </div>
                  <div class="item" id="success7">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/7.svg"/>
                  </div>
                  <div class="item" id="success8">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff' src="./static/images/qualitative/8.svg"/>
                  </div>
                  <div class="item" id="success9">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff'  src="./static/images/qualitative/9.svg"/>
                  </div>
                  <div class="item" id="success10">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff; border-right:4vw solid #ffffff;' src="./static/images/qualitative/10.svg"/>
                  </div>
                  <div class="item" id="success11">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff;  border-right:4vw solid #ffffff' src="./static/images/qualitative/11.svg"/>
                  </div>
                  <div class="item" id="success12">
                    <img  style='border-top:2vh solid #ffffff; border-bottom:2vh solid #ffffff; border-left:4vw solid #ffffff;  border-right:4vw solid #ffffff' src="./static/images/qualitative/12.svg"/>
                  </div>
                  

                </div>
              </div>
              <p id="success-text">Javascript Required</p>
              
            </div>
          </div>

        </div>
      <h3 class="title is-4">Natural Support for Uncertainty Quantification</h3>
      
          <!-- <p>3DNEL MSIGP achieves accuracy on par with SOTA, and outperforms ablations on YCB-V. We report Average Recall on YCB-V in the sim-to-real setup using RGB-D inputs. Results for 3DNEL MSIGP are averaged over 5 runs. Standard deviation is below 0.2% for all setups. 3DNEL MSIGP significantly outperforms SurfEMB depiste using the same underlying models, highlighting the benefits of 3DNEL’s principled probabilistic modeling. -->
          </p>
          <br>

      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
            <img src="./static/images/pose_uncertainty.svg" />
        </div>
      </div>
   </div>

    <br><br><br>


      <div class="container is-max-desktop">
        <h3 class="title is-4">Extension to additional tasks without task-specific retraining</h3>
        <h4 class="title is-5">Object Pose Tracking Through Occlusion</h4>
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <img src="./static/images/tracking_synthetic.gif" />
          </div>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <img  width="40%" src="./static/images/tracking_1.gif" />
          </div>
        </div>

        <h4 class="title is-5">Camera Pose Tracking</h4>
            <p>We demonstrate that 3DNEL’s probabilistic formulation
              provides a principled framework for incorporating prior
              knowledge about the scene and objects, and enables easy
              extension to camera pose tracking from video using probabilistic inference in the same model without task specific retraining.</p>
            <br>
      </div>
  


      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Few-shot Object Pose Estimation Using DINOv2 Embeddings</h2>
	</div>
        
            <p>So far our experiments reuse components from SurfEMB
              to highlight the added benefits of robustness and uncertainty
              quantification from 3DNEL’s principled probabilistic modeling. However, 3DNEL can leverage any learned neural
              embeddings and similarity measurements. To illustrate this,
              we demonstrate applying 3DNEL to a simple few-shot pose
              estimation task in simulation using similarity measurements
              based on learned neural embeddings from DINOv2, a
              recently released vision foundation model.

	      <br><br>

              <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <img src="./static/images/dino.svg" />
                </div>
              </div>
      
      
            </div>

    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://arxiv.org/abs/2302.03744">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/google-deepmind/threednel" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a
                href="https://github.com/probcomp/nel">source code</a> of this website, which
              itelf is a fork of <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
              We just ask that you link back to this page in the footer.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
